{"last_scenario": 0, "total_steps": 50000, "model_name": "PPO_Naive_Combined"}