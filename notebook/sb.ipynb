{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "base_path = os.path.join(os.getcwd(), \"..\")\n",
    "print(f\"Base Path: {base_path}\")\n",
    "sys.path.append(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swkim/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Stable baselines3\n",
    "import stable_baselines3 as sb3\n",
    "\n",
    "# env\n",
    "import gym\n",
    "from kube_sim_gym.envs.sim_kube_env import SimKubeEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "from kube_mm_scheduler.model.promes import Net5_\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PromesPPO(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(PromesPPO, self).__init__(observation_space, features_dim)\n",
    "        self.net = Net5_().to(device)\n",
    "        self.net.load_state_dict(th.load(os.path.join(base_path,'kube_mm_scheduler/weight/net5.pt')))\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        input1 = observations[:, :10].to(device)\n",
    "        input2 = observations[:, 10:].to(device)\n",
    "\n",
    "        return self.net(input1, input2)\n",
    "    \n",
    "class Naive(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(Naive, self).__init__(observation_space, features_dim)\n",
    "        self.net = nn.Linear(observation_space.shape[0], features_dim).to(device)\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.net(observations)\n",
    "\n",
    "policy_kwargs_promes = dict(\n",
    "    features_extractor_class=PromesPPO,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")\n",
    "\n",
    "policy_kwargs_naive = dict(\n",
    "    features_extractor_class=Naive,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. sb3 naive dqn with static reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m'\u001b[39m\u001b[39mSimKubeEnv-v0\u001b[39m\u001b[39m'\u001b[39m, reward_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstatic.py\u001b[39m\u001b[39m'\u001b[39m, scenario_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscenario-5l-5m-1000p-10m.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Model : Naive dqn\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m sb3_naive_dqn_static \u001b[39m=\u001b[39m sb3\u001b[39m.\u001b[39;49mDQN(\u001b[39m'\u001b[39;49m\u001b[39mMlpPolicy\u001b[39;49m\u001b[39m'\u001b[39;49m, env, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\u001b[39m300000\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/dqn/dqn.py:258\u001b[0m, in \u001b[0;36mDQN.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    246\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    247\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    256\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DQN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    259\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    260\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    261\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    262\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    263\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    264\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    265\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    266\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    267\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    268\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    344\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    346\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 347\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    348\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    349\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    350\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    351\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    352\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    353\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    354\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    357\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:580\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    577\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    579\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    582\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    583\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:11\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     10\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset, \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m observation, reward, done, info\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/envs/sim_kube_env.py:155\u001b[0m, in \u001b[0;36mSimKubeEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m--> 155\u001b[0m     env_prev \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mduplicate()\n\u001b[1;32m    157\u001b[0m     \u001b[39m# self.time += 1\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# is_scheduled = None\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m     \u001b[39m# Update cluster\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime)\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/envs/sim_kube_env.py:63\u001b[0m, in \u001b[0;36mSimKubeEnv.duplicate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m     62\u001b[0m new_env \u001b[39m=\u001b[39m SimKubeEnvCopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_file, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenario_file, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_node, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcpu_pool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem_pool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug)\n\u001b[0;32m---> 63\u001b[0m new_env\u001b[39m.\u001b[39mcluster \u001b[39m=\u001b[39m deepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster)\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m new_env\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:205\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    203\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[0;32m--> 205\u001b[0m     append(deepcopy(a, memo))\n\u001b[1;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "env = gym.make('SimKubeEnv-v0', reward_file='static.py', scenario_file='scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "# Model : Naive dqn\n",
    "sb3_naive_dqn_static = sb3.DQN('MlpPolicy', env, verbose=1).learn(300000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sb3 naive dqn with dynamic reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | -1.4e+03 |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 5135     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.673     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 162       |\n",
      "|    total_timesteps  | 10330     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.44e+03 |\n",
      "|    exploration_rate | 0.509     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 245       |\n",
      "|    total_timesteps  | 15521     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.346     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 326       |\n",
      "|    total_timesteps  | 20657     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.181     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 408       |\n",
      "|    total_timesteps  | 25855     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 490       |\n",
      "|    total_timesteps  | 31022     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 572       |\n",
      "|    total_timesteps  | 36192     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 655       |\n",
      "|    total_timesteps  | 41418     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 63        |\n",
      "|    time_elapsed     | 734       |\n",
      "|    total_timesteps  | 46503     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.34e+03  |\n",
      "|    ep_rew_mean      | -1.67e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 61        |\n",
      "|    time_elapsed     | 868       |\n",
      "|    total_timesteps  | 53631     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.679     |\n",
      "|    n_updates        | 907       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | -1.6e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 954      |\n",
      "|    total_timesteps  | 58738    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 2184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | -1.5e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 61       |\n",
      "|    time_elapsed     | 1028     |\n",
      "|    total_timesteps  | 63416    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.723    |\n",
      "|    n_updates        | 3353     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.31e+03  |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 61        |\n",
      "|    time_elapsed     | 1102      |\n",
      "|    total_timesteps  | 68064     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.17      |\n",
      "|    n_updates        | 4515      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.3e+03   |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 61        |\n",
      "|    time_elapsed     | 1177      |\n",
      "|    total_timesteps  | 72713     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.647     |\n",
      "|    n_updates        | 5678      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.29e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 61        |\n",
      "|    time_elapsed     | 1250      |\n",
      "|    total_timesteps  | 77345     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.163     |\n",
      "|    n_updates        | 6836      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.28e+03  |\n",
      "|    ep_rew_mean      | -1.23e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 61        |\n",
      "|    time_elapsed     | 1322      |\n",
      "|    total_timesteps  | 81931     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.667     |\n",
      "|    n_updates        | 7982      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.27e+03  |\n",
      "|    ep_rew_mean      | -1.17e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 62        |\n",
      "|    time_elapsed     | 1394      |\n",
      "|    total_timesteps  | 86535     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.743     |\n",
      "|    n_updates        | 9133      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.27e+03  |\n",
      "|    ep_rew_mean      | -1.12e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 62        |\n",
      "|    time_elapsed     | 1466      |\n",
      "|    total_timesteps  | 91136     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.543     |\n",
      "|    n_updates        | 10283     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.26e+03  |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 62        |\n",
      "|    time_elapsed     | 1538      |\n",
      "|    total_timesteps  | 95717     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.511     |\n",
      "|    n_updates        | 11429     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.25e+03  |\n",
      "|    ep_rew_mean      | -1.04e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 62        |\n",
      "|    time_elapsed     | 1610      |\n",
      "|    total_timesteps  | 100304    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.925     |\n",
      "|    n_updates        | 12575     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.25e+03  |\n",
      "|    ep_rew_mean      | -1.01e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 62        |\n",
      "|    time_elapsed     | 1682      |\n",
      "|    total_timesteps  | 104908    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.341     |\n",
      "|    n_updates        | 13726     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -963     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 1753     |\n",
      "|    total_timesteps  | 109490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 14872    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -938     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 1825     |\n",
      "|    total_timesteps  | 114088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.64     |\n",
      "|    n_updates        | 16021    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 1897     |\n",
      "|    total_timesteps  | 118674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.394    |\n",
      "|    n_updates        | 17168    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 1969     |\n",
      "|    total_timesteps  | 123264   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.494    |\n",
      "|    n_updates        | 18315    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -860     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2040     |\n",
      "|    total_timesteps  | 127827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 19456    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -826     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2111     |\n",
      "|    total_timesteps  | 132394   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 20598    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -777     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2183     |\n",
      "|    total_timesteps  | 136983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 21745    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.21e+03 |\n",
      "|    ep_rew_mean      | -722     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2255     |\n",
      "|    total_timesteps  | 141582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.849    |\n",
      "|    n_updates        | 22895    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -679     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2334     |\n",
      "|    total_timesteps  | 146167   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 24041    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.2e+03  |\n",
      "|    ep_rew_mean      | -616     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2408     |\n",
      "|    total_timesteps  | 150775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 25193    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.19e+03 |\n",
      "|    ep_rew_mean      | -571     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2480     |\n",
      "|    total_timesteps  | 155369   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.455    |\n",
      "|    n_updates        | 26342    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.19e+03 |\n",
      "|    ep_rew_mean      | -522     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2551     |\n",
      "|    total_timesteps  | 159948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.859    |\n",
      "|    n_updates        | 27486    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.18e+03 |\n",
      "|    ep_rew_mean      | -501     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2627     |\n",
      "|    total_timesteps  | 164693   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 28673    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -379     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2703     |\n",
      "|    total_timesteps  | 169456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 29863    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -370     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2777     |\n",
      "|    total_timesteps  | 174127   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.576    |\n",
      "|    n_updates        | 31031    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -385     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2854     |\n",
      "|    total_timesteps  | 178924   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.667    |\n",
      "|    n_updates        | 32230    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -383     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 2927     |\n",
      "|    total_timesteps  | 183579   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.552    |\n",
      "|    n_updates        | 33394    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -377     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3001     |\n",
      "|    total_timesteps  | 188231   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.663    |\n",
      "|    n_updates        | 34557    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -384     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3075     |\n",
      "|    total_timesteps  | 192881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.513    |\n",
      "|    n_updates        | 35720    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -403     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3151     |\n",
      "|    total_timesteps  | 197646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.712    |\n",
      "|    n_updates        | 36911    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -397     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3224     |\n",
      "|    total_timesteps  | 202262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 38065    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -405     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3296     |\n",
      "|    total_timesteps  | 206880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.868    |\n",
      "|    n_updates        | 39219    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -411     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3369     |\n",
      "|    total_timesteps  | 211500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.997    |\n",
      "|    n_updates        | 40374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -417     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3442     |\n",
      "|    total_timesteps  | 216152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.533    |\n",
      "|    n_updates        | 41537    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -412     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3514     |\n",
      "|    total_timesteps  | 220768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.624    |\n",
      "|    n_updates        | 42691    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -422     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3587     |\n",
      "|    total_timesteps  | 225390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 43847    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -420     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3659     |\n",
      "|    total_timesteps  | 229993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.969    |\n",
      "|    n_updates        | 44998    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -411     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3732     |\n",
      "|    total_timesteps  | 234628   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 46156    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -406     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3804     |\n",
      "|    total_timesteps  | 239212   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.331    |\n",
      "|    n_updates        | 47302    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -404     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3877     |\n",
      "|    total_timesteps  | 243829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.57     |\n",
      "|    n_updates        | 48457    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -385     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 3950     |\n",
      "|    total_timesteps  | 248475   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.799    |\n",
      "|    n_updates        | 49618    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -388     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4023     |\n",
      "|    total_timesteps  | 253096   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.763    |\n",
      "|    n_updates        | 50773    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -392     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4096     |\n",
      "|    total_timesteps  | 257708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.586    |\n",
      "|    n_updates        | 51926    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -393     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4169     |\n",
      "|    total_timesteps  | 262335   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.671    |\n",
      "|    n_updates        | 53083    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -404     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4242     |\n",
      "|    total_timesteps  | 266955   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 54238    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -405     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4314     |\n",
      "|    total_timesteps  | 271572   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.592    |\n",
      "|    n_updates        | 55392    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -402     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4386     |\n",
      "|    total_timesteps  | 276153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.627    |\n",
      "|    n_updates        | 56538    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -391     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4458     |\n",
      "|    total_timesteps  | 280759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.349    |\n",
      "|    n_updates        | 57689    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -365     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 62       |\n",
      "|    time_elapsed     | 4529     |\n",
      "|    total_timesteps  | 285334   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 58833    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -352     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4601     |\n",
      "|    total_timesteps  | 289939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 59984    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -330     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4674     |\n",
      "|    total_timesteps  | 294557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.543    |\n",
      "|    n_updates        | 61139    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -324     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 63       |\n",
      "|    time_elapsed     | 4746     |\n",
      "|    total_timesteps  | 299180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 62294    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "env = gym.make('SimKubeEnv-v0', reward_file='dynamic.py', scenario_file='scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "# Model : Naive dqn\n",
    "sb3_naive_dqn_dynamic = sb3.DQN('MlpPolicy', env, verbose=1).learn(300000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. sb3 promes dqn with static reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m'\u001b[39m\u001b[39mSimKubeEnv-v0\u001b[39m\u001b[39m'\u001b[39m, reward_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstatic.py\u001b[39m\u001b[39m'\u001b[39m, scenario_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscenario-5l-5m-1000p-10m.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Model : Promes dqn\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m sb3_promes_dqn_static \u001b[39m=\u001b[39m sb3\u001b[39m.\u001b[39;49mDQN(\u001b[39m'\u001b[39;49m\u001b[39mMlpPolicy\u001b[39;49m\u001b[39m'\u001b[39;49m, env, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, policy_kwargs\u001b[39m=\u001b[39;49mpolicy_kwargs)\u001b[39m.\u001b[39;49mlearn(\u001b[39m300000\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/dqn/dqn.py:258\u001b[0m, in \u001b[0;36mDQN.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    246\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    247\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    256\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DQN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    259\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    260\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    261\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    262\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    263\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    264\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    265\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    266\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    267\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    268\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    344\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    346\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 347\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[1;32m    348\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[1;32m    349\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[1;32m    350\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[1;32m    351\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    352\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[1;32m    353\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[1;32m    354\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    357\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:580\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    577\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[1;32m    579\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[1;32m    582\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    583\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:11\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     10\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset, \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m observation, reward, done, info\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from kube_mm_scheduler.model.promes import Net5_\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PromesDQN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(PromesDQN, self).__init__(observation_space, features_dim)\n",
    "        self.net = Net5_().to(device)\n",
    "        self.net.load_state_dict(th.load(os.path.join(base_path,'kube_mm_scheduler/weight/net5.pt')))\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        input1 = observations[:, :10].to(device)\n",
    "        input2 = observations[:, 10:].to(device)\n",
    "\n",
    "        return self.net(input1, input2)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=PromesDQN,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")\n",
    "\n",
    "# Environment\n",
    "env = gym.make('SimKubeEnv-v0', reward_file='static.py', scenario_file='scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "# Model : Promes dqn\n",
    "sb3_promes_dqn_static = sb3.DQN('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs).learn(300000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. sb3 promes dqn with dynamic reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to log_dir_dqn_dynamic\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.3e+03   |\n",
      "|    ep_rew_mean      | -1.44e+03 |\n",
      "|    exploration_rate | 0.836     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 59        |\n",
      "|    time_elapsed     | 87        |\n",
      "|    total_timesteps  | 5185      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.673     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 2046      |\n",
      "|    total_timesteps  | 10340     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.509     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 7         |\n",
      "|    time_elapsed     | 2130      |\n",
      "|    total_timesteps  | 15516     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.345     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 9         |\n",
      "|    time_elapsed     | 2214      |\n",
      "|    total_timesteps  | 20682     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.182     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 11        |\n",
      "|    time_elapsed     | 2299      |\n",
      "|    total_timesteps  | 25831     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.41e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 13        |\n",
      "|    time_elapsed     | 2382      |\n",
      "|    total_timesteps  | 30980     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.41e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 14        |\n",
      "|    time_elapsed     | 2464      |\n",
      "|    total_timesteps  | 36155     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 16        |\n",
      "|    time_elapsed     | 2546      |\n",
      "|    total_timesteps  | 41327     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 17        |\n",
      "|    time_elapsed     | 2630      |\n",
      "|    total_timesteps  | 46551     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.35e+03  |\n",
      "|    ep_rew_mean      | -1.69e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 19        |\n",
      "|    time_elapsed     | 2773      |\n",
      "|    total_timesteps  | 53899     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.282     |\n",
      "|    n_updates        | 974       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.41e+03  |\n",
      "|    ep_rew_mean      | -1.97e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 20        |\n",
      "|    time_elapsed     | 2965      |\n",
      "|    total_timesteps  | 61842     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.922     |\n",
      "|    n_updates        | 2960      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.39e+03  |\n",
      "|    ep_rew_mean      | -1.86e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 21        |\n",
      "|    time_elapsed     | 3059      |\n",
      "|    total_timesteps  | 66928     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.479     |\n",
      "|    n_updates        | 4231      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.38e+03  |\n",
      "|    ep_rew_mean      | -1.78e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 22        |\n",
      "|    time_elapsed     | 3144      |\n",
      "|    total_timesteps  | 71658     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.654     |\n",
      "|    n_updates        | 5414      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.36e+03  |\n",
      "|    ep_rew_mean      | -1.69e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 23        |\n",
      "|    time_elapsed     | 3225      |\n",
      "|    total_timesteps  | 76301     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.725     |\n",
      "|    n_updates        | 6575      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.35e+03  |\n",
      "|    ep_rew_mean      | -1.57e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 24        |\n",
      "|    time_elapsed     | 3307      |\n",
      "|    total_timesteps  | 80908     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.26      |\n",
      "|    n_updates        | 7726      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.34e+03  |\n",
      "|    ep_rew_mean      | -1.51e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 25        |\n",
      "|    time_elapsed     | 3387      |\n",
      "|    total_timesteps  | 85543     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.918     |\n",
      "|    n_updates        | 8885      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.33e+03  |\n",
      "|    ep_rew_mean      | -1.44e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 25        |\n",
      "|    time_elapsed     | 3469      |\n",
      "|    total_timesteps  | 90176     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.875     |\n",
      "|    n_updates        | 10043     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.32e+03  |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 26        |\n",
      "|    time_elapsed     | 3548      |\n",
      "|    total_timesteps  | 94824     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.453     |\n",
      "|    n_updates        | 11205     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.31e+03  |\n",
      "|    ep_rew_mean      | -1.32e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 27        |\n",
      "|    time_elapsed     | 3626      |\n",
      "|    total_timesteps  | 99421     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.602     |\n",
      "|    n_updates        | 12355     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.3e+03   |\n",
      "|    ep_rew_mean      | -1.27e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 3696      |\n",
      "|    total_timesteps  | 104043    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.49      |\n",
      "|    n_updates        | 13510     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.29e+03  |\n",
      "|    ep_rew_mean      | -1.23e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 28        |\n",
      "|    time_elapsed     | 3765      |\n",
      "|    total_timesteps  | 108635    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.475     |\n",
      "|    n_updates        | 14658     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+03 |\n",
      "|    ep_rew_mean      | -1.2e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 3833     |\n",
      "|    total_timesteps  | 113215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.857    |\n",
      "|    n_updates        | 15803    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.28e+03  |\n",
      "|    ep_rew_mean      | -1.17e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 30        |\n",
      "|    time_elapsed     | 3902      |\n",
      "|    total_timesteps  | 117836    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.768     |\n",
      "|    n_updates        | 16958     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.28e+03  |\n",
      "|    ep_rew_mean      | -1.13e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 30        |\n",
      "|    time_elapsed     | 3978      |\n",
      "|    total_timesteps  | 122455    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.46      |\n",
      "|    n_updates        | 18113     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.27e+03  |\n",
      "|    ep_rew_mean      | -1.09e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 31        |\n",
      "|    time_elapsed     | 4064      |\n",
      "|    total_timesteps  | 127072    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.794     |\n",
      "|    n_updates        | 19267     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.27e+03  |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 31        |\n",
      "|    time_elapsed     | 4139      |\n",
      "|    total_timesteps  | 131693    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.457     |\n",
      "|    n_updates        | 20423     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 1.26e+03  |\n",
      "|    ep_rew_mean      | -1.01e+03 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 32        |\n",
      "|    time_elapsed     | 4211      |\n",
      "|    total_timesteps  | 136309    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.291     |\n",
      "|    n_updates        | 21577     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 4280     |\n",
      "|    total_timesteps  | 140891   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.52     |\n",
      "|    n_updates        | 22722    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+03 |\n",
      "|    ep_rew_mean      | -920     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 4349     |\n",
      "|    total_timesteps  | 145486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 23871    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 4419     |\n",
      "|    total_timesteps  | 150108   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 25026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.24e+03 |\n",
      "|    ep_rew_mean      | -828     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 4490     |\n",
      "|    total_timesteps  | 154725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.509    |\n",
      "|    n_updates        | 26181    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -782     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 4573     |\n",
      "|    total_timesteps  | 159330   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 27332    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.23e+03 |\n",
      "|    ep_rew_mean      | -743     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 4651     |\n",
      "|    total_timesteps  | 163937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.297    |\n",
      "|    n_updates        | 28484    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.22e+03 |\n",
      "|    ep_rew_mean      | -687     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 4729     |\n",
      "|    total_timesteps  | 168536   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.716    |\n",
      "|    n_updates        | 29633    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.19e+03 |\n",
      "|    ep_rew_mean      | -530     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4806     |\n",
      "|    total_timesteps  | 173126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.391    |\n",
      "|    n_updates        | 30781    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.16e+03 |\n",
      "|    ep_rew_mean      | -359     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4883     |\n",
      "|    total_timesteps  | 177708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.648    |\n",
      "|    n_updates        | 31926    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -345     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 4960     |\n",
      "|    total_timesteps  | 182302   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.616    |\n",
      "|    n_updates        | 33075    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -323     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 5041     |\n",
      "|    total_timesteps  | 186936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 34233    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -306     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 5120     |\n",
      "|    total_timesteps  | 191538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.717    |\n",
      "|    n_updates        | 35384    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -316     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 5203     |\n",
      "|    total_timesteps  | 196143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.328    |\n",
      "|    n_updates        | 36535    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -297     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 5279     |\n",
      "|    total_timesteps  | 200690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.683    |\n",
      "|    n_updates        | 37672    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -297     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 5361     |\n",
      "|    total_timesteps  | 205290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 38822    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -307     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 5440     |\n",
      "|    total_timesteps  | 209909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 39977    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -320     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 5519     |\n",
      "|    total_timesteps  | 214518   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.711    |\n",
      "|    n_updates        | 41129    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -319     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 5606     |\n",
      "|    total_timesteps  | 219112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.724    |\n",
      "|    n_updates        | 42277    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -311     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 5682     |\n",
      "|    total_timesteps  | 223674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.73     |\n",
      "|    n_updates        | 43418    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -306     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 5760     |\n",
      "|    total_timesteps  | 228271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 44567    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 39       |\n",
      "|    time_elapsed     | 5837     |\n",
      "|    total_timesteps  | 232861   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.801    |\n",
      "|    n_updates        | 45715    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -292     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 5918     |\n",
      "|    total_timesteps  | 237462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.697    |\n",
      "|    n_updates        | 46865    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -303     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 5996     |\n",
      "|    total_timesteps  | 242074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.566    |\n",
      "|    n_updates        | 48018    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -293     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 6071     |\n",
      "|    total_timesteps  | 246621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.864    |\n",
      "|    n_updates        | 49155    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -297     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 40       |\n",
      "|    time_elapsed     | 6148     |\n",
      "|    total_timesteps  | 251200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.727    |\n",
      "|    n_updates        | 50299    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -293     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 6226     |\n",
      "|    total_timesteps  | 255801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 51450    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -294     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 6303     |\n",
      "|    total_timesteps  | 260385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.547    |\n",
      "|    n_updates        | 52596    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 6380     |\n",
      "|    total_timesteps  | 264972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 53742    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -296     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 6457     |\n",
      "|    total_timesteps  | 269554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.434    |\n",
      "|    n_updates        | 54888    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -310     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 41       |\n",
      "|    time_elapsed     | 6534     |\n",
      "|    total_timesteps  | 274171   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.425    |\n",
      "|    n_updates        | 56042    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 6612     |\n",
      "|    total_timesteps  | 278772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.593    |\n",
      "|    n_updates        | 57192    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -301     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 6689     |\n",
      "|    total_timesteps  | 283343   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 58335    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -310     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 6766     |\n",
      "|    total_timesteps  | 287931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.727    |\n",
      "|    n_updates        | 59482    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -299     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 6843     |\n",
      "|    total_timesteps  | 292508   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.5      |\n",
      "|    n_updates        | 60626    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.15e+03 |\n",
      "|    ep_rew_mean      | -295     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 42       |\n",
      "|    time_elapsed     | 6918     |\n",
      "|    total_timesteps  | 297054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.767    |\n",
      "|    n_updates        | 61763    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common import logger\n",
    "\n",
    "from kube_mm_scheduler.model.promes import Net5_\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PromesDQN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(PromesDQN, self).__init__(observation_space, features_dim)\n",
    "        self.net = Net5_().to(device)\n",
    "        self.net.load_state_dict(th.load(os.path.join(base_path,'kube_mm_scheduler/weight/net5.pt')))\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        input1 = observations[:, :10].to(device)\n",
    "        input2 = observations[:, 10:].to(device)\n",
    "\n",
    "        return self.net(input1, input2)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=PromesDQN,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")\n",
    "\n",
    "# Environment\n",
    "env = gym.make('SimKubeEnv-v0', reward_file='dynamic.py', scenario_file='scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "# Model : Promes dqn\n",
    "sb3_promes_dqn_dynamic = sb3.DQN('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs).learn(300000)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. sb3 promes PPO with static reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to log_dir_sac_static\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.26e+03 |\n",
      "|    ep_rew_mean     | 1.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 68       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | 1.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011766098 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -0.00166    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 91.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | 1.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012584902 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.00383     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933809 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -0.000497   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 1.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017078392 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -6.41e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 1.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016712712 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -4.54e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | 1.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011859021 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 1.04e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 1.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013941878 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -8.7e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 1.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018686028 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -2.26e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011872294 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -7.15e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    value_loss           | 89.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009922137 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -7.75e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012440439 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -4.89e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.3        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011923527 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -2.74e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013122192 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -1.19e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | 1.24e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 510          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093541015 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | -1.91e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 67.3         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011525401 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -8.34e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 578         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002218275 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.5        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000539   |\n",
      "|    value_loss           | 86.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012445505 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | -8.34e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | 1.26e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 648          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077666314 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | -8.34e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 84.2         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010917926 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010019958 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006829899 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | -8.34e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.21e+03   |\n",
      "|    ep_rew_mean          | 1.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 785        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01215011 |\n",
      "|    clip_fraction        | 0.0753     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | -7.15e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 85.2       |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00177   |\n",
      "|    value_loss           | 143        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 816         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006383791 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.21e+03   |\n",
      "|    ep_rew_mean          | 1.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 850        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01085721 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.61      |\n",
      "|    explained_variance   | -1.67e-06  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 71.4       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00808   |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 886         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006606513 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | -8.34e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 920         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015222279 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -8.34e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | 1.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 952          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114948535 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -1.91e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014656009 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1024        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006643394 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -1.79e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009606853 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.000924   |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.2e+03   |\n",
      "|    ep_rew_mean          | 1.28e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 1088      |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0102381 |\n",
      "|    clip_fraction        | 0.0957    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.59     |\n",
      "|    explained_variance   | -1.19e-06 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 146       |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -0.00474  |\n",
      "|    value_loss           | 171       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1123        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016830165 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89.6        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.2e+03   |\n",
      "|    ep_rew_mean          | 1.29e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 1158      |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0121157 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.59     |\n",
      "|    explained_variance   | -7.15e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 130       |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -0.00173  |\n",
      "|    value_loss           | 162       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007248234 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 91.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | 1.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1223         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068590227 |\n",
      "|    clip_fraction        | 0.098        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | -3.58e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | 1.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 1259         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072302837 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | -4.77e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 238          |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1292        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010855062 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | 1.29e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 1324       |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01282501 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -3.58e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 62.1       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00363   |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1358        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014659638 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00013    |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1394        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009093584 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89.1        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1427        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004937242 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1459        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012601316 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1493        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010055538 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1529        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020805035 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1561        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009479707 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1593        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008052677 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1627        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005968674 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1663        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011199944 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1696        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009192409 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | 1.31e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 1727         |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060445843 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1761        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008728909 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1796        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009544557 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1830        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014144994 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1861        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008334216 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1894        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008989138 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.3        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008545019 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1964        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010640115 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.000512   |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1995        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018226974 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 2027        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011153029 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -9.54e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 2061        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009511475 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | 1.45e-05    |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 2096        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012417907 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.8        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 2128        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008046832 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.000954   |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2161        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016846098 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | 0.000546    |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 2196        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015140355 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -1.07e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 2232        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011660935 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -7.15e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 2267        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011261297 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 2298        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013341491 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 2330        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012564263 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.5        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | 1.36e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 2363         |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079366695 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 93           |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.000221    |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 2398        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010690218 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.2        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 2431        |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009201443 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.000637    |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 2463        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010331154 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | 1.36e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 2496         |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117138075 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | -3.58e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 67.3         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.17e+03   |\n",
      "|    ep_rew_mean          | 1.37e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 2530       |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01226558 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 195        |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    value_loss           | 169        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 2566        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011229321 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 2596        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019504957 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2628        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013208511 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 2662        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013884058 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.5        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 7.93e-05    |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014526348 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.000302   |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 2730        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012206709 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 2761        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013071804 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 2794        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014262028 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -5.96e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 2828        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010297181 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | 1.38e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 2863         |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080840485 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 228          |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | 1.39e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 2895       |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01000841 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.46      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 200        |\n",
      "|    n_updates            | 850        |\n",
      "|    policy_gradient_loss | -0.00168   |\n",
      "|    value_loss           | 168        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 2926        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015948199 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 2959        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013049543 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.3        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | 1.39e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 2993       |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01953888 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 69.2       |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | 0.00104    |\n",
      "|    value_loss           | 167        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 3028        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007435429 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | 0.000476    |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | 1.39e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 3059       |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01608387 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 94.2       |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 3090       |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01348686 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.43      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56         |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.00425   |\n",
      "|    value_loss           | 154        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 3124        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009133164 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.000506    |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 3158       |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01405971 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.43      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 65.3       |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.00317   |\n",
      "|    value_loss           | 198        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 3193        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036692932 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 3224        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014771801 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 3257        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015943008 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 3292        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026597466 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 3326        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011064373 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 3357        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013859879 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.1        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 3390        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015984807 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.8        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.000448   |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 3424        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019806907 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 3459        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014019284 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.15e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 3491       |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01294837 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 172        |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | -0.00121   |\n",
      "|    value_loss           | 181        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 3522        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029412735 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 3555        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018558938 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 3590        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017112475 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | 0.000891    |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.15e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 3625       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01702195 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.44      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 147        |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.000481  |\n",
      "|    value_loss           | 182        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 3656        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015963284 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.9        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 3688        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014497671 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.2        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | 0.000999    |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 3722        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026023088 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 3757        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023142481 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.2        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 3789        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019402305 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.4        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.15e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 3820       |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02375064 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 31.8       |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.00633   |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 3854        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020802803 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | 0.0027      |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 3889        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016142907 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 3922        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013487912 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 3954        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011729628 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 3986        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016167153 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 4021        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013731644 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.000165    |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 4056        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022924505 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | 0.00441     |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 4087        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019683897 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | 0.000383    |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 4119        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046828546 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | 0.000122    |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.15e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 4153       |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01620819 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 96.1       |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.00224   |\n",
      "|    value_loss           | 188        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 4188        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017278984 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 4221        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012614137 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 4252        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020640196 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 4285        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011317427 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 4319        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014021786 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 4354        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015315966 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.8        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.15e+03   |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 4385       |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01887704 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 53         |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 4417        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011840172 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.1        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 4450        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019567203 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 4485        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009716792 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 4518        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018640567 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 4549        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019554775 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 4582        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012825092 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 4617        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010162991 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 4651        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014748866 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.9        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.15e+03   |\n",
      "|    ep_rew_mean          | 1.39e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 140        |\n",
      "|    time_elapsed         | 4682       |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01783678 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 48.5       |\n",
      "|    n_updates            | 1390       |\n",
      "|    policy_gradient_loss | -0.00584   |\n",
      "|    value_loss           | 133        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 4715        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013845737 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 4749        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014732167 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 4785        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013389982 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 4815        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016604386 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 4847        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013116001 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.15e+03     |\n",
      "|    ep_rew_mean          | 1.39e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 4881         |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107925655 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.9         |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 4917        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020312756 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common import logger\n",
    "\n",
    "from kube_mm_scheduler.model.promes import Net5_\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PromesPPO(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(PromesPPO, self).__init__(observation_space, features_dim)\n",
    "        self.net = Net5_().to(device)\n",
    "        self.net.load_state_dict(th.load(os.path.join(base_path,'kube_mm_scheduler/weight/net5.pt')))\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        input1 = observations[:, :10].to(device)\n",
    "        input2 = observations[:, 10:].to(device)\n",
    "\n",
    "        return self.net(input1, input2)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=PromesPPO,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")\n",
    "\n",
    "# Environment\n",
    "env = gym.make('SimKubeEnv-v0', reward_file='static.py', scenario_file='scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "# Logger\n",
    "logger.configure(\"log_dir_sac_static\")\n",
    "\n",
    "# Model : Promes dqn\n",
    "sb3_promes_ppo_static = sb3.PPO('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs).learn(300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (sb3_promes_ppo_static)\n",
    "sb3_promes_ppo_static.save(\"sb3_promes_ppo_static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (sb3_promes_ppo_static)\n",
    "sb3_promes_ppo_static = sb3.PPO.load(\"sb3_promes_ppo_static\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. sb3 promes PPO with dynamic reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to log_dir_sac_dynamic\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.29e+03 |\n",
      "|    ep_rew_mean     | -1.4e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 65       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.28e+03   |\n",
      "|    ep_rew_mean          | -1.34e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 59         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01033981 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | -0.0163    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 63.9       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    value_loss           | 160        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.28e+03    |\n",
      "|    ep_rew_mean          | -1.35e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014722416 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.0648      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -1.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012617356 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.00366     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.26e+03  |\n",
      "|    ep_rew_mean          | -1.25e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 177       |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0157162 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.74     |\n",
      "|    explained_variance   | 0.00783   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 43.9      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0136   |\n",
      "|    value_loss           | 127       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -1.22e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010702994 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -1.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008412042 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.0928      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.24e+03   |\n",
      "|    ep_rew_mean          | -1.16e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01465714 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.0108     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 51.4       |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -1.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015055578 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.23e+03     |\n",
      "|    ep_rew_mean          | -1.07e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 352          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045550964 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 68.8         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -8.57e-06    |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | -1.06e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010888705 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.23e+03     |\n",
      "|    ep_rew_mean          | -1.01e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 425          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071766023 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 78.6         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 226          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -990        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005735241 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -976        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015038345 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    value_loss           | 90.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -949        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007629077 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -931        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010454344 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.5        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -906        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008876336 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -908         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110625625 |\n",
      "|    clip_fraction        | 0.0607       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.1         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -869        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016804598 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.9        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -867        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 705         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008352814 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.9        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -851        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004526946 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    value_loss           | 96.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -820         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 774          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041105305 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 93.5         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000307    |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -820        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007751737 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -813        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012373099 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -799        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 893         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013496313 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -769        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007715781 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 368         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -771         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 967          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068776063 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 147          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 333          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -744         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1000         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024294308 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.841        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000386    |\n",
      "|    value_loss           | 378          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -716        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012441669 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    value_loss           | 476         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.21e+03   |\n",
      "|    ep_rew_mean          | -706       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 57         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 1076       |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691354 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 332        |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 570        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -683        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1113        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016604032 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64          |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 344         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | -661       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 1153       |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00855428 |\n",
      "|    clip_fraction        | 0.0599     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 194        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    value_loss           | 534        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -649        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008958349 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 415         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    value_loss           | 512         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -644        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1224        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012778349 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 270         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 487         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -633        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012616623 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | -619       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 1293       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01204548 |\n",
      "|    clip_fraction        | 0.0605     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 163        |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00819   |\n",
      "|    value_loss           | 432        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -613        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1331        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017008338 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    value_loss           | 473         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -600        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1364        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018408792 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 175         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -585        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1403        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013363704 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 245         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    value_loss           | 466         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -581        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1440        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011943746 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | -575       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 1475       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00690093 |\n",
      "|    clip_fraction        | 0.0369     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 144        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00178   |\n",
      "|    value_loss           | 290        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -567        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1508        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010797244 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -559        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011444304 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -552        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1583        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014240612 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 375         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -540        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1616        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004980867 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -528        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1650        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005522458 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -515        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1687        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011555539 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    value_loss           | 406         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -514         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1722         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075570373 |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    value_loss           | 352          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -513        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009198186 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -512        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1793        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014385455 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -512        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1835        |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011999827 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | -507       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 56         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 1872       |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01328843 |\n",
      "|    clip_fraction        | 0.0738     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.6       |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 79.7       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.00864   |\n",
      "|    value_loss           | 164        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -502        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1910        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011786104 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.8        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -492        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1945        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010613053 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -490        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1977        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009900263 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -487         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 2008         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054224627 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 63.2         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -482         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 2042         |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065445267 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 92.5         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -477        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 2079        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010458417 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -476         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 2112         |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070490474 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -449         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 2143         |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058424934 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71           |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -424        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 2174        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014354607 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 99.8        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -402        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 2209        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008532982 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -391        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 2237        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010827474 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.9        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -371        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2268        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008912051 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.6        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 2301        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017674336 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.3        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -340         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 57           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 2335         |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087490175 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 254          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -325        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 2365        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012264894 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 2399        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012400272 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    value_loss           | 250         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -302        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011507372 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.19e+03   |\n",
      "|    ep_rew_mean          | -303       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 2470       |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01292254 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 77.8       |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.00795   |\n",
      "|    value_loss           | 197        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -292         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 2502         |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066245953 |\n",
      "|    clip_fraction        | 0.0786       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -278         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 2539         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099373935 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 78.6         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 2576        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011667443 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.5        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -264         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 2608         |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120045915 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.5         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -253        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 2643        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014880407 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -238        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 2680        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007693176 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -232        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 2718        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012567929 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -221        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2751        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009784701 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -209        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 2784        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010464098 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -212        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 2819        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007978411 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69          |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -205        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 2854        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007823287 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -192        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 2886        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011223154 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 94.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.19e+03   |\n",
      "|    ep_rew_mean          | -182       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 2921       |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01081779 |\n",
      "|    clip_fraction        | 0.0911     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 48.9       |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.00807   |\n",
      "|    value_loss           | 127        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.19e+03   |\n",
      "|    ep_rew_mean          | -180       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 2958       |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01034159 |\n",
      "|    clip_fraction        | 0.0575     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.8       |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.00437   |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 2994        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010577964 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -171        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 3026        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498549 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -170        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 3059        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010220356 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 3094        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008346921 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -175        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 3130        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005752214 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -181        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 3162        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011624868 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -184         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 3195         |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072167423 |\n",
      "|    clip_fraction        | 0.0997       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -174        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 3232        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012706187 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -176         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 3266         |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097057205 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.3         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -172        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 3299        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011982991 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -167        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 3331        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011004064 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    value_loss           | 71          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -164         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 3363         |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119656855 |\n",
      "|    clip_fraction        | 0.0853       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00924     |\n",
      "|    value_loss           | 99.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -162         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 3396         |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074065374 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.6         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 92.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -154        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 3426        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007549803 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -148        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 3461        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007062367 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -145        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 3497        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008857414 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -142        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 3534        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010119422 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -141        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 3567        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007636263 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 91.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -142        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 3602        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007359819 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 90.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -149        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 3639        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986429 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -148        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 3674        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008434761 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -138        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 3707        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007042559 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    value_loss           | 99.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -129         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 3742         |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057238066 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -118         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 3778         |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143505065 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    value_loss           | 91.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 3814        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005743388 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.18e+03   |\n",
      "|    ep_rew_mean          | -110       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 58         |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 3846       |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00513263 |\n",
      "|    clip_fraction        | 0.0833     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.56      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.8       |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | -0.00535   |\n",
      "|    value_loss           | 75.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 3881        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011567012 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -98.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 3917        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010278832 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    value_loss           | 81.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -96          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 3953         |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062477486 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43.5         |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -84.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 3986        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010746569 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 87.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -80         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 4020        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006696175 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -81.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 4056         |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103057865 |\n",
      "|    clip_fraction        | 0.0724       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.6         |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -80.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 4093        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013068636 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    value_loss           | 92.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -80.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 4126        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010957461 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    value_loss           | 89.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -87.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 4160        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009298714 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -88.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 4196        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008464907 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -92.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 4233        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011026886 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -92.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 4265        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010263606 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 83.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -89.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 4299         |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124403555 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.5         |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 77.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -91.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 4334        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008631514 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 88.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -86.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 4371        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012498373 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -83.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 4404        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009094935 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -75.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 4438        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007376857 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -70.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 4475        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007964192 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -66.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 4513        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009944065 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    value_loss           | 92.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -65.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 4549        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010336902 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -64.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 4583        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009997216 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -63.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 4619        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012261549 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -58.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 4653        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011946388 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -58.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 4691        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011777386 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -58.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 4720         |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057197334 |\n",
      "|    clip_fraction        | 0.0691       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 86.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -58         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 4749        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663895 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -47.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 4780        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006683535 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -45.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 4810        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012525177 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 81.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -45.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 4837        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010802103 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -44.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 4865         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067127743 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 73.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -41.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 4895        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008624543 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.17e+03  |\n",
      "|    ep_rew_mean          | -39.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 142       |\n",
      "|    time_elapsed         | 4926      |\n",
      "|    total_timesteps      | 290816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0110307 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.54     |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 30.5      |\n",
      "|    n_updates            | 1410      |\n",
      "|    policy_gradient_loss | -0.0091   |\n",
      "|    value_loss           | 77        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -36.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 4953        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007212593 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -33.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 4981        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010598699 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -24         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 5009        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005052331 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.000829   |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -12.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 5039        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008137342 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    value_loss           | 74.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -10.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 5069        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004956752 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common import logger\n",
    "\n",
    "from kube_mm_scheduler.model.promes import Net5_\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PromesPPO(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(PromesPPO, self).__init__(observation_space, features_dim)\n",
    "        self.net = Net5_().to(device)\n",
    "        self.net.load_state_dict(th.load(os.path.join(base_path,'kube_mm_scheduler/weight/net5.pt')))\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        input1 = observations[:, :10].to(device)\n",
    "        input2 = observations[:, 10:].to(device)\n",
    "\n",
    "        return self.net(input1, input2)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=PromesPPO,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")\n",
    "\n",
    "# Environment\n",
    "env = gym.make('SimKubeEnv-v0', reward_file='dynamic.py', scenario_file='scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "# Model : Promes dqn\n",
    "sb3_promes_ppo_dynamic = sb3.PPO('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs).learn(300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (sb3_promes_ppo_dynamic)\n",
    "sb3_promes_ppo_dynamic.save(\"sb3_promes_ppo_dynamic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (sb3_promes_ppo_dynamic)\n",
    "sb3_promes_ppo_dynamic = sb3.PPO.load(\"sb3_promes_ppo_dynamic\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Promes PPO with real data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1> Only Dynamic Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "from kube_mm_scheduler.model.promes import Net5_\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PromesPPO(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 80):\n",
    "        super(PromesPPO, self).__init__(observation_space, features_dim)\n",
    "        self.net = Net5_().to(device)\n",
    "        self.net.load_state_dict(th.load(os.path.join(base_path,'kube_mm_scheduler/weight/net5.pt')))\n",
    "        self.net.eval()\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        input1 = observations[:, :10].to(device)\n",
    "        input2 = observations[:, 10:].to(device)\n",
    "\n",
    "        return self.net(input1, input2)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=PromesPPO,\n",
    "    features_extractor_kwargs=dict(features_dim=80),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "envs = []\n",
    "for i in range(1, 101):\n",
    "    env = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "envs.append(env)\n",
    "\n",
    "print(len(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training(json_tracker_fname):\n",
    "\n",
    "    log_name = json_tracker_fname.split('.')[0]\n",
    "    log_path = 'training/log/' + log_name\n",
    "\n",
    "    new_logger = configure(log_path, [\"tensorboard\", \"stdout\"])\n",
    "\n",
    "    # Load the json tracker\n",
    "    import json\n",
    "    with open(f'training/{json_tracker_fname}', 'r') as f:\n",
    "        json_tracker = json.load(f)\n",
    "\n",
    "    # Check if the last scenario is None\n",
    "    if json_tracker['last_scenario'] == 0:\n",
    "        # If it is None, then start from the first scenario\n",
    "        scenario_idx = 1\n",
    "    else:\n",
    "        # If it is not None, then continue from the last scenario\n",
    "        scenario_idx = int(json_tracker['last_scenario']) + 1\n",
    "\n",
    "    # Load the last scenario\n",
    "    env, = envs[scenario_idx - 1]\n",
    "    print(f\"Loading the scenario: {env.scenario_file}\")\n",
    "\n",
    "    # Load the last model. If there is model_name doesn't exist in training/model folder, then start from the scratch\n",
    "    model_name = json_tracker['model_name']\n",
    "    if os.path.exists(f'training/model/{model_name}.zip'):\n",
    "        print(f\"Loading the model: {model_name}\")\n",
    "        model = sb3.PPO.load(f'training/model/{model_name}.zip')\n",
    "        # Set the environment\n",
    "        model.set_env(env)\n",
    "    else:\n",
    "        print(f\"Model {model_name} doesn't exist. Start from the scratch.\")\n",
    "        model = sb3.PPO('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    # ============================== Performance Test ===============================\n",
    "\n",
    "    # Previous model performance test (vs. defautl scheduler)\n",
    "    # Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "    # Default Scheduler\n",
    "    from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "    default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "    # Test the model\n",
    "    obs1 = test_env1.reset()\n",
    "    obs2 = test_env2.reset()\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    step1 = 0\n",
    "    step2 = 0\n",
    "    acc_rew1 = 0\n",
    "    acc_rew2 = 0\n",
    "\n",
    "    print(\"Start testing...\")\n",
    "    while not done1 or not done2:\n",
    "        if not done1:\n",
    "            action1, _ = model.predict(obs1)\n",
    "            obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "            step1 += 1\n",
    "            acc_rew1 += reward1\n",
    "        if not done2:\n",
    "            action2 = default_scheduler.decision(test_env2)\n",
    "            obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "            step2 += 1\n",
    "            acc_rew2 += reward2\n",
    "\n",
    "    print(f\"Test result(reward): {acc_rew1} vs. {acc_rew2}\")\n",
    "    print(f\"Test result(step): {step1} vs. {step2}\")\n",
    "\n",
    "    # Append it to the log file\n",
    "    with open(f'training/log/{log_name}/test_result.txt', 'a') as f:\n",
    "        f.write(f\"Test result after {scenario_idx - 1}th training\\n\")\n",
    "        f.write(f\"- reward : {acc_rew1} vs. {acc_rew2}\\n\")\n",
    "        f.write(f\"- step : {step1} vs. {step2}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # ============================== ==================== ===============================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Set the logger\n",
    "    model.set_logger(new_logger)\n",
    "\n",
    "    total_timesteps = json_tracker['total_steps']\n",
    "\n",
    "    # Start training\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    # Update the json tracker\n",
    "    json_tracker['last_scenario'] = scenario_idx\n",
    "\n",
    "    # Save the json tracker\n",
    "    with open(f'training/{json_tracker_fname}', 'w') as f:\n",
    "        json.dump(json_tracker, f)\n",
    "\n",
    "    return json_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to training/log/tracker_ppo_promes_combined\n",
      "Loading the scenario: trace2017/trace2017_100_23.csv\n",
      "Loading the model: PPO_Promes_Combined\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Start testing...\n",
      "Test result(reward): -313.8599999999993 vs. 239.8400000000005\n",
      "Test result(step): 1190 vs. 1105\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | -437     |\n",
      "| time/              |          |\n",
      "|    fps             | 35       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -480        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019311816 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.6         |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | 0.00566     |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -461        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013670247 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.09e+03   |\n",
      "|    ep_rew_mean          | -456       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01195357 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | 0.864      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.64       |\n",
      "|    n_updates            | 11030      |\n",
      "|    policy_gradient_loss | -0.00758   |\n",
      "|    value_loss           | 48         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -450        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010669028 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -445        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012961459 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -438        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008252918 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -434        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011356501 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -436        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010003673 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    value_loss           | 96          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -435        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015941367 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -437         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 34           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 650          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137353055 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 11100        |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -432        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016094033 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -424        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 771         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010298767 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 58.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -420        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012033993 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -416        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 889         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011567202 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -415        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014213255 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 88.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m n_scenario \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mscenarios\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrace2017\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m last_idx \u001b[39m<\u001b[39m n_scenario:\n\u001b[0;32m----> 9\u001b[0m     json_tracker \u001b[39m=\u001b[39m keep_training(\u001b[39m'\u001b[39;49m\u001b[39mtracker_ppo_promes_combined.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     last_idx \u001b[39m=\u001b[39m json_tracker[\u001b[39m'\u001b[39m\u001b[39mlast_scenario\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[12], line 92\u001b[0m, in \u001b[0;36mkeep_training\u001b[0;34m(json_tracker_fname)\u001b[0m\n\u001b[1;32m     89\u001b[0m total_timesteps \u001b[39m=\u001b[39m json_tracker[\u001b[39m'\u001b[39m\u001b[39mtotal_steps\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     91\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps)\n\u001b[1;32m     94\u001b[0m \u001b[39m# Training for env2\u001b[39;00m\n\u001b[1;32m     95\u001b[0m model\u001b[39m.\u001b[39mset_env(env2)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:304\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    293\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    302\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPPO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(PPO, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    305\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    306\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    307\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    308\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    309\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    310\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    311\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    312\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    314\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:270\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mrecord(\u001b[39m\"\u001b[39m\u001b[39mtime/total_timesteps\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps, exclude\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdump(step\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps)\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    272\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    274\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:203\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_sde:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mreset_noise(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size)\n\u001b[0;32m--> 203\u001b[0m values, log_prob, entropy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mevaluate_actions(rollout_data\u001b[39m.\u001b[39;49mobservations, actions)\n\u001b[1;32m    204\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    205\u001b[0m \u001b[39m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/policies.py:643\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[39mEvaluate actions according to the current policy,\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mgiven the observations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39m    and entropy of the action distribution.\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m# Preprocess the observation if needed\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(obs)\n\u001b[1;32m    644\u001b[0m latent_pi, latent_vf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor(features)\n\u001b[1;32m    645\u001b[0m distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/policies.py:129\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mNo features extractor was set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m preprocessed_obs \u001b[39m=\u001b[39m preprocess_obs(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, normalize_images\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_extractor(preprocessed_obs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/folders/gl/n3l9mrsx1jz4xhb0rsxhj8980000gn/T/ipykernel_74804/1368690018.py:24\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, observations)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_mm_scheduler/model/promes.py:44\u001b[0m, in \u001b[0;36mNet5_.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     42\u001b[0m x3_3 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1_3_3(x1[:, \u001b[39m4\u001b[39m:\u001b[39m6\u001b[39m]))\n\u001b[1;32m     43\u001b[0m x3_4 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1_3_4(x1[:, \u001b[39m6\u001b[39m:\u001b[39m8\u001b[39m]))\n\u001b[0;32m---> 44\u001b[0m x3_5 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1_3_5(x1[:, \u001b[39m8\u001b[39;49m:\u001b[39m10\u001b[39;49m]))\n\u001b[1;32m     46\u001b[0m x4_1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x12, x3_1), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m x4_2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x12, x3_2), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# Get n_scenario by counting the number of trace files in trace folder\n",
    "n_scenario = len(os.listdir(os.path.join(base_path, 'scenarios', 'trace2017')))\n",
    "\n",
    "while last_idx < n_scenario:\n",
    "    json_tracker = keep_training('tracker_ppo_promes_combined.json')\n",
    "    last_idx = json_tracker['last_scenario']\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2> PROMES Static + Dynamic Combination Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "envs = []\n",
    "for i in range(1, 101):\n",
    "    env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    env2 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    envs.append((env1, env2))\n",
    "\n",
    "print(len(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training(json_tracker_fname):\n",
    "\n",
    "    log_name = json_tracker_fname.split('.')[0]\n",
    "    log_path = 'training/log/' + log_name\n",
    "\n",
    "    # Load the json tracker\n",
    "    import json\n",
    "    with open(f'training/{json_tracker_fname}', 'r') as f:\n",
    "        json_tracker = json.load(f)\n",
    "\n",
    "    # Check if the last scenario is None\n",
    "    if json_tracker['last_scenario'] == 0:\n",
    "        # If it is None, then start from the first scenario\n",
    "        scenario_idx = 1\n",
    "    else:\n",
    "        # If it is not None, then continue from the last scenario\n",
    "        scenario_idx = int(json_tracker['last_scenario']) + 1\n",
    "\n",
    "    # Load the last scenario\n",
    "    env1, env2 = envs[scenario_idx - 1]\n",
    "    print(f\"Loading the scenario: {env1.scenario_file}\")\n",
    "\n",
    "    # Load the last model. If there is model_name doesn't exist in training/model folder, then start from the scratch\n",
    "    model_name = json_tracker['model_name']\n",
    "    if os.path.exists(f'training/model/{model_name}.zip'):\n",
    "        print(f\"Loading the model: {model_name}\")\n",
    "        model = sb3.PPO.load(f'training/model/{model_name}.zip')\n",
    "        # Set the environment\n",
    "        model.set_env(env1)\n",
    "    else:\n",
    "        print(f\"Model {model_name} doesn't exist. Start from the scratch.\")\n",
    "        model = sb3.PPO('MlpPolicy', env1, verbose=1, policy_kwargs=policy_kwargs_promes)\n",
    "\n",
    "\n",
    "\n",
    "    # ============================== Performance Test ===============================\n",
    "\n",
    "    # Previous model performance test (vs. defautl scheduler)\n",
    "    # Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "    # Default Scheduler\n",
    "    from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "    default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "    # Test the model\n",
    "    obs1 = test_env1.reset()\n",
    "    obs2 = test_env2.reset()\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    step1 = 0\n",
    "    step2 = 0\n",
    "    acc_rew1 = 0\n",
    "    acc_rew2 = 0\n",
    "\n",
    "    print(\"Start testing...\")\n",
    "    while not done1 or not done2:\n",
    "        if not done1:\n",
    "            action1, _ = model.predict(obs1)\n",
    "            obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "            step1 += 1\n",
    "            acc_rew1 += reward1\n",
    "        if not done2:\n",
    "            action2 = default_scheduler.decision(test_env2)\n",
    "            obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "            step2 += 1\n",
    "            acc_rew2 += reward2\n",
    "\n",
    "    print(f\"Test result(reward): {acc_rew1} vs. {acc_rew2}\")\n",
    "    print(f\"Test result(step): {step1} vs. {step2}\")\n",
    "\n",
    "    # Append it to the log file\n",
    "\n",
    "    # Make folder if it doesn't exist\n",
    "    if not os.path.exists(f'training/log/{log_name}'):\n",
    "        os.makedirs(f'training/log/{log_name}')\n",
    "\n",
    "    with open(f'training/log/{log_name}/test_result.txt', 'a') as f:\n",
    "        f.write(f\"{scenario_idx - 1}, {acc_rew2}, {step2}, {acc_rew1}, {step1}\\n\")\n",
    "        # f.write(f\"Test result after {scenario_idx - 1}th training\\n\")\n",
    "        # f.write(f\"- reward : {acc_rew1} vs. {acc_rew2}\\n\")\n",
    "        # f.write(f\"- step : {step1} vs. {step2}\\n\")\n",
    "        # f.write(\"\\n\")\n",
    "\n",
    "    # ============================== ==================== ===============================\n",
    "\n",
    "    total_timesteps = json_tracker['total_steps']\n",
    "\n",
    "    # Start training\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Training for env2\n",
    "    model.set_env(env2)\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    # Update the json tracker\n",
    "    json_tracker['last_scenario'] = scenario_idx\n",
    "\n",
    "    # Save the json tracker\n",
    "    with open(f'training/{json_tracker_fname}', 'w') as f:\n",
    "        json.dump(json_tracker, f)\n",
    "\n",
    "    return json_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# Get n_scenario by counting the number of trace files in trace folder\n",
    "n_scenario = len(os.listdir(os.path.join(base_path, 'scenarios', 'trace2017')))\n",
    "\n",
    "while last_idx < n_scenario:\n",
    "    json_tracker = keep_training('tracker_ppo_promes_combined.json')\n",
    "    last_idx = json_tracker['last_scenario']\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3> Static w/ Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/..\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "envs = []\n",
    "for i in range(1, 101):\n",
    "    env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static_step_1.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    envs.append((env1))\n",
    "\n",
    "print(len(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training(json_tracker_fname):\n",
    "\n",
    "    log_name = json_tracker_fname.split('.')[0]\n",
    "    log_path = 'training/log/' + log_name\n",
    "\n",
    "    # Load the json tracker\n",
    "    import json\n",
    "    with open(f'training/{json_tracker_fname}', 'r') as f:\n",
    "        json_tracker = json.load(f)\n",
    "\n",
    "    # Check if the last scenario is None\n",
    "    if json_tracker['last_scenario'] == 0:\n",
    "        # If it is None, then start from the first scenario\n",
    "        scenario_idx = 1\n",
    "    else:\n",
    "        # If it is not None, then continue from the last scenario\n",
    "        scenario_idx = int(json_tracker['last_scenario']) + 1\n",
    "\n",
    "    # Load the last scenario\n",
    "    env1 = envs[scenario_idx - 1]\n",
    "    print(f\"Loading the scenario: {env1.scenario_file}\")\n",
    "\n",
    "    # Load the last model. If there is model_name doesn't exist in training/model folder, then start from the scratch\n",
    "    model_name = json_tracker['model_name']\n",
    "    if os.path.exists(f'training/model/{model_name}.zip'):\n",
    "        print(f\"Loading the model: {model_name}\")\n",
    "        model = sb3.PPO.load(f'training/model/{model_name}.zip')\n",
    "        # Set the environment\n",
    "        model.set_env(env1)\n",
    "    else:\n",
    "        print(f\"Model {model_name} doesn't exist. Start from the scratch.\")\n",
    "        model = sb3.PPO('MlpPolicy', env1, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "    # ============================== Performance Test ===============================\n",
    "\n",
    "    # Previous model performance test (vs. defautl scheduler)\n",
    "    # Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "    # Default Scheduler\n",
    "    from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "    default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "    # Test the model\n",
    "    obs1 = test_env1.reset()\n",
    "    obs2 = test_env2.reset()\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    step1 = 0\n",
    "    step2 = 0\n",
    "    acc_rew1 = 0\n",
    "    acc_rew2 = 0\n",
    "\n",
    "    print(\"Start testing...\")\n",
    "    while not done1 or not done2:\n",
    "        if not done1:\n",
    "            action1, _ = model.predict(obs1)\n",
    "            obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "            step1 += 1\n",
    "            acc_rew1 += reward1\n",
    "        if not done2:\n",
    "            action2 = default_scheduler.decision(test_env2)\n",
    "            obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "            step2 += 1\n",
    "            acc_rew2 += reward2\n",
    "\n",
    "    print(f\"Test result(reward): {acc_rew1} vs. {acc_rew2}\")\n",
    "    print(f\"Test result(step): {step1} vs. {step2}\")\n",
    "\n",
    "    # Append it to the log file\n",
    "\n",
    "    # Make folder if it doesn't exist\n",
    "    if not os.path.exists(f'training/log/{log_name}'):\n",
    "        os.makedirs(f'training/log/{log_name}')\n",
    "\n",
    "    with open(f'training/log/{log_name}/test_result.txt', 'a') as f:\n",
    "        f.write(f\"Test result after {scenario_idx - 1}th training\\n\")\n",
    "        f.write(f\"- reward : {acc_rew1} vs. {acc_rew2}\\n\")\n",
    "        f.write(f\"- step : {step1} vs. {step2}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # ============================== ==================== ===============================\n",
    "\n",
    "\n",
    "    total_timesteps = json_tracker['total_steps']\n",
    "\n",
    "    # Start training\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # # Training for env2\n",
    "    # model.set_env(env2)\n",
    "    # model.learn(total_timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    # Update the json tracker\n",
    "    json_tracker['last_scenario'] = scenario_idx\n",
    "\n",
    "    # Save the json tracker\n",
    "    with open(f'training/{json_tracker_fname}', 'w') as f:\n",
    "        json.dump(json_tracker, f)\n",
    "\n",
    "    return json_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the scenario: trace2017/trace2017_100_3.csv\n",
      "Loading the model: PPO_Static_Step\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Start testing...\n",
      "Test result(reward): -33723.739999999816 vs. -316.58000000000044\n",
      "Test result(step): 4741 vs. 1102\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 31   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 65   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009506434 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m n_scenario \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mscenarios\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrace2017\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m last_idx \u001b[39m<\u001b[39m n_scenario:\n\u001b[0;32m----> 9\u001b[0m     json_tracker \u001b[39m=\u001b[39m keep_training(\u001b[39m'\u001b[39;49m\u001b[39mtracker_ppo_static_step.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     last_idx \u001b[39m=\u001b[39m json_tracker[\u001b[39m'\u001b[39m\u001b[39mlast_scenario\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 91\u001b[0m, in \u001b[0;36mkeep_training\u001b[0;34m(json_tracker_fname)\u001b[0m\n\u001b[1;32m     88\u001b[0m total_timesteps \u001b[39m=\u001b[39m json_tracker[\u001b[39m'\u001b[39m\u001b[39mtotal_steps\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     90\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps)\n\u001b[1;32m     93\u001b[0m \u001b[39m# # Training for env2\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# model.set_env(env2)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m# model.learn(total_timesteps)\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m     98\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining/model/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:304\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    293\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    302\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPPO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(PPO, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    305\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    306\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    307\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    308\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    309\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[1;32m    310\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[1;32m    311\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    312\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[1;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    314\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    246\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    248\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 250\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, gym\u001b[39m.\u001b[39mspaces\u001b[39m.\u001b[39mBox):\n\u001b[1;32m    176\u001b[0m     clipped_actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mlow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mhigh)\n\u001b[0;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(clipped_actions)\n\u001b[1;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[1;32m    182\u001b[0m \u001b[39m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/stable_baselines3/common/monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:11\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     10\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset, \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m observation, reward, done, info\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/envs/sim_kube_env.py:155\u001b[0m, in \u001b[0;36mSimKubeEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m--> 155\u001b[0m     env_prev \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mduplicate()\n\u001b[1;32m    157\u001b[0m     \u001b[39m# self.time += 1\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# is_scheduled = None\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m     \u001b[39m# Update cluster\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime)\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/envs/sim_kube_env.py:63\u001b[0m, in \u001b[0;36mSimKubeEnv.duplicate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m     62\u001b[0m new_env \u001b[39m=\u001b[39m SimKubeEnvCopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_file, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenario_file, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_node, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcpu_pool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmem_pool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug)\n\u001b[0;32m---> 63\u001b[0m new_env\u001b[39m.\u001b[39mcluster \u001b[39m=\u001b[39m deepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster)\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m new_env\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:205\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    203\u001b[0m append \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mappend\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[0;32m--> 205\u001b[0m     append(deepcopy(a, memo))\n\u001b[1;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/copy.py:138\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    135\u001b[0m     memo \u001b[39m=\u001b[39m {}\n\u001b[1;32m    137\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mid\u001b[39m(x)\n\u001b[0;32m--> 138\u001b[0m y \u001b[39m=\u001b[39m memo\u001b[39m.\u001b[39;49mget(d, _nil)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _nil:\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# Get n_scenario by counting the number of trace files in trace folder\n",
    "n_scenario = len(os.listdir(os.path.join(base_path, 'scenarios', 'trace2017')))\n",
    "\n",
    "while last_idx < n_scenario:\n",
    "    json_tracker = keep_training('tracker_ppo_static_step.json')\n",
    "    last_idx = json_tracker['last_scenario']\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4> Naive Static + Dynamic Combination Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "envs = []\n",
    "for i in range(1, 101):\n",
    "    env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    env2 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    envs.append((env1, env2))\n",
    "\n",
    "print(len(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training(json_tracker_fname):\n",
    "\n",
    "    log_name = json_tracker_fname.split('.')[0]\n",
    "    log_path = 'training/log/' + log_name\n",
    "\n",
    "    # Load the json tracker\n",
    "    import json\n",
    "    with open(f'training/{json_tracker_fname}', 'r') as f:\n",
    "        json_tracker = json.load(f)\n",
    "\n",
    "    # Check if the last scenario is None\n",
    "    if json_tracker['last_scenario'] == 0:\n",
    "        # If it is None, then start from the first scenario\n",
    "        scenario_idx = 1\n",
    "    else:\n",
    "        # If it is not None, then continue from the last scenario\n",
    "        scenario_idx = int(json_tracker['last_scenario']) + 1\n",
    "\n",
    "    # Load the last scenario\n",
    "    env1, env2 = envs[scenario_idx - 1]\n",
    "    print(f\"Loading the scenario: {env1.scenario_file}\")\n",
    "\n",
    "    # Load the last model. If there is model_name doesn't exist in training/model folder, then start from the scratch\n",
    "    model_name = json_tracker['model_name']\n",
    "    if os.path.exists(f'training/model/{model_name}.zip'):\n",
    "        print(f\"Loading the model: {model_name}\")\n",
    "        model = sb3.PPO.load(f'training/model/{model_name}.zip')\n",
    "        # Set the environment\n",
    "        model.set_env(env1)\n",
    "    else:\n",
    "        print(f\"Model {model_name} doesn't exist. Start from the scratch.\")\n",
    "        model = sb3.PPO('MlpPolicy', env1, verbose=1, policy_kwargs=policy_kwargs_naive)\n",
    "\n",
    "\n",
    "\n",
    "    # ============================== Performance Test ===============================\n",
    "\n",
    "    # Previous model performance test (vs. defautl scheduler)\n",
    "    # Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_static.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "    # Default Scheduler\n",
    "    from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "    default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "    # Test the model\n",
    "    obs1 = test_env1.reset()\n",
    "    obs2 = test_env2.reset()\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    step1 = 0\n",
    "    step2 = 0\n",
    "    acc_rew1 = 0\n",
    "    acc_rew2 = 0\n",
    "\n",
    "    print(\"Start testing...\")\n",
    "    while not done1 or not done2:\n",
    "        if not done1:\n",
    "            action1, _ = model.predict(obs1)\n",
    "            obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "            step1 += 1\n",
    "            acc_rew1 += reward1\n",
    "        if not done2:\n",
    "            action2 = default_scheduler.decision(test_env2)\n",
    "            obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "            step2 += 1\n",
    "            acc_rew2 += reward2\n",
    "\n",
    "    print(f\"Test result(reward): {acc_rew1} vs. {acc_rew2}\")\n",
    "    print(f\"Test result(step): {step1} vs. {step2}\")\n",
    "\n",
    "    # Append it to the log file\n",
    "\n",
    "    # Make folder if it doesn't exist\n",
    "    if not os.path.exists(f'training/log/{log_name}'):\n",
    "        os.makedirs(f'training/log/{log_name}')\n",
    "\n",
    "    with open(f'training/log/{log_name}/test_result.txt', 'a') as f:\n",
    "        f.write(\"step, d_reward, d_step, p_reward, p_step\\n\")\n",
    "        f.write(f\"{scenario_idx - 1}, {acc_rew2}, {step2}, {acc_rew1}, {step1}\\n\")\n",
    "        # f.write(f\"Test result after {scenario_idx - 1}th training\\n\")\n",
    "        # f.write(f\"- reward : {acc_rew1} vs. {acc_rew2}\\n\")\n",
    "        # f.write(f\"- step : {step1} vs. {step2}\\n\")\n",
    "        # f.write(\"\\n\")\n",
    "\n",
    "    # ============================== ==================== ===============================\n",
    "\n",
    "    total_timesteps = json_tracker['total_steps']\n",
    "\n",
    "    # Start training\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Training for env2\n",
    "    model.set_env(env2)\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    # Update the json tracker\n",
    "    json_tracker['last_scenario'] = scenario_idx\n",
    "\n",
    "    # Save the json tracker\n",
    "    with open(f'training/{json_tracker_fname}', 'w') as f:\n",
    "        json.dump(json_tracker, f)\n",
    "\n",
    "    return json_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# Get n_scenario by counting the number of trace files in trace folder\n",
    "n_scenario = len(os.listdir(os.path.join(base_path, 'scenarios', 'trace2017')))\n",
    "\n",
    "while last_idx < n_scenario:\n",
    "    json_tracker = keep_training('tracker_ppo_naive_combined.json')\n",
    "    last_idx = json_tracker['last_scenario']\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5> PPO Promes Dynamic New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "envs = []\n",
    "for i in range(1, 101):\n",
    "    env = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    envs.append(env)\n",
    "\n",
    "print(len(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(scenario_file, model_name, log_name, scenario_idx):\n",
    "    # ============================== Performance Test ===============================\n",
    "\n",
    "    # Previous model performance test (vs. defautl scheduler)\n",
    "    # Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=scenario_file)\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=scenario_file)\n",
    "\n",
    "    # Default Scheduler\n",
    "    from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "    default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "    # RL Scheduler\n",
    "    from kube_rl_scheduler.scheduler.sim_rl_scheduler import SimRlScheduler\n",
    "    rl_scheduler = SimRlScheduler(test_env1, f'_{model_name}.zip')\n",
    "\n",
    "\n",
    "    # Test the model\n",
    "    obs1 = test_env1.reset()\n",
    "    obs2 = test_env2.reset()\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    step1 = 0\n",
    "    step2 = 0\n",
    "    acc_rew1 = 0\n",
    "    acc_rew2 = 0\n",
    "\n",
    "    print(\"Start testing...\")\n",
    "    while not done1 or not done2:\n",
    "        if not done1:\n",
    "            # action1, _ = model.predict(obs1)\n",
    "            action1 = rl_scheduler.decision(test_env1)\n",
    "            obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "            step1 += 1\n",
    "            acc_rew1 += reward1\n",
    "        if not done2:\n",
    "            action2 = default_scheduler.decision(test_env2)\n",
    "            obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "            step2 += 1\n",
    "            acc_rew2 += reward2\n",
    "\n",
    "    acc_rew1 = round(acc_rew1, 2)\n",
    "    acc_rew2 = round(acc_rew2, 2)\n",
    "\n",
    "    print(f\"Test result(reward): {acc_rew1} vs. {acc_rew2}\")\n",
    "    print(f\"Test result(step): {step1} vs. {step2}\")\n",
    "\n",
    "    return acc_rew1, acc_rew2, step1, step2\n",
    "\n",
    "    # ============================== ==================== ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training(json_tracker_fname):\n",
    "\n",
    "    log_name = json_tracker_fname.split('.')[0]\n",
    "    log_path = 'training/log/' + log_name\n",
    "\n",
    "    # Load the json tracker\n",
    "    import json\n",
    "    with open(f'training/{json_tracker_fname}', 'r') as f:\n",
    "        json_tracker = json.load(f)\n",
    "\n",
    "    # Check if the last scenario is None\n",
    "    if json_tracker['last_scenario'] == 0:\n",
    "        # If it is None, then start from the first scenario\n",
    "        scenario_idx = 1\n",
    "    else:\n",
    "        # If it is not None, then continue from the last scenario\n",
    "        scenario_idx = int(json_tracker['last_scenario']) + 1\n",
    "\n",
    "    # Load the last scenario\n",
    "    env = envs[scenario_idx - 1]\n",
    "    print(f\"Loading the scenario: {env.scenario_file}\")\n",
    "\n",
    "    # Load the last model. If there is model_name doesn't exist in training/model folder, then start from the scratch\n",
    "    model_name = json_tracker['model_name']\n",
    "    if os.path.exists(f'training/model/{model_name}.zip'):\n",
    "        print(f\"Loading the model: {model_name}\")\n",
    "        model = sb3.PPO.load(f'training/model/{model_name}.zip')\n",
    "        # Set the environment\n",
    "        model.set_env(env)\n",
    "    else:\n",
    "        print(f\"Model {model_name} doesn't exist. Start from the scratch.\")\n",
    "        model = sb3.PPO('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs_promes)\n",
    "        model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    a1, a2, a3, a4 = test_model('scenario-5l-5m-1000p-10m.csv', model_name, log_name, scenario_idx)\n",
    "    b1, b2, b3, b4 = test_model('scenario-3l-10m-1000p-10m.csv', model_name, log_name, scenario_idx)\n",
    "    c1, c2, c3, c4 = test_model('scenario-10l-3m-1000p-10m.csv', model_name, log_name, scenario_idx)\n",
    "\n",
    "    # Append it to the log file\n",
    "\n",
    "    # Make folder if it doesn't exist\n",
    "    if not os.path.exists(f'training/log/{log_name}'):\n",
    "        os.makedirs(f'training/log/{log_name}')\n",
    "\n",
    "    with open(f'training/log/{log_name}/test_result.txt', 'a') as f:\n",
    "        # f.write(\"step, d_reward, d_step, p_reward, p_step\\n\")\n",
    "        f.write(f\"{scenario_idx - 1}, {a1}, {a2}, {a3}, {a4}, {b1}, {b2}, {b3}, {b4}, {c1}, {c2}, {c3}, {c4}\\n\")\n",
    "\n",
    "    total_timesteps = json_tracker['total_steps']\n",
    "\n",
    "    # Start training\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    # Update the json tracker\n",
    "    json_tracker['last_scenario'] = scenario_idx\n",
    "\n",
    "    # Save the json tracker\n",
    "    with open(f'training/{json_tracker_fname}', 'w') as f:\n",
    "        json.dump(json_tracker, f)\n",
    "\n",
    "    return json_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the scenario: trace2017/trace2017_100_11.csv\n",
      "Loading the model: PPO_Promes_Dynamic_New\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Start testing...\n",
      "Test result(reward): 208.75 vs. 192.27\n",
      "Test result(step): 1120 vs. 1102\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Start testing...\n",
      "Test result(reward): 266.74 vs. 235.95\n",
      "Test result(step): 1274 vs. 1261\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/utils/../../scenarios/scenario_10l-3m-1000p-10m.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m n_scenario \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mscenarios\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrace2017\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m last_idx \u001b[39m<\u001b[39m n_scenario:\n\u001b[0;32m----> 9\u001b[0m     json_tracker \u001b[39m=\u001b[39m keep_training(\u001b[39m'\u001b[39;49m\u001b[39mtracker_ppo_promes_dynamic_new.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     last_idx \u001b[39m=\u001b[39m json_tracker[\u001b[39m'\u001b[39m\u001b[39mlast_scenario\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m, in \u001b[0;36mkeep_training\u001b[0;34m(json_tracker_fname)\u001b[0m\n\u001b[1;32m     35\u001b[0m a1, a2, a3, a4 \u001b[39m=\u001b[39m test_model(\u001b[39m'\u001b[39m\u001b[39mscenario-5l-5m-1000p-10m.csv\u001b[39m\u001b[39m'\u001b[39m, model_name, log_name, scenario_idx)\n\u001b[1;32m     36\u001b[0m b1, b2, b3, b4 \u001b[39m=\u001b[39m test_model(\u001b[39m'\u001b[39m\u001b[39mscenario-3l-10m-1000p-10m.csv\u001b[39m\u001b[39m'\u001b[39m, model_name, log_name, scenario_idx)\n\u001b[0;32m---> 37\u001b[0m c1, c2, c3, c4 \u001b[39m=\u001b[39m test_model(\u001b[39m'\u001b[39;49m\u001b[39mscenario_10l-3m-1000p-10m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, model_name, log_name, scenario_idx)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Append it to the log file\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Make folder if it doesn't exist\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining/log/\u001b[39m\u001b[39m{\u001b[39;00mlog_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(scenario_file, model_name, log_name, scenario_idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_model\u001b[39m(scenario_file, model_name, log_name, scenario_idx):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# ============================== Performance Test ===============================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m     \u001b[39m# Previous model performance test (vs. defautl scheduler)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Test scenario : scenario-5l-5m-1000p-10m.csv\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     test_env1 \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mSimKubeEnv-v0\u001b[39;49m\u001b[39m'\u001b[39;49m, reward_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpromes_dynamic_new.py\u001b[39;49m\u001b[39m'\u001b[39;49m, scenario_file\u001b[39m=\u001b[39;49mscenario_file)\n\u001b[1;32m      7\u001b[0m     test_env2 \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m'\u001b[39m\u001b[39mSimKubeEnv-v0\u001b[39m\u001b[39m'\u001b[39m, reward_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpromes_dynamic_new.py\u001b[39m\u001b[39m'\u001b[39m, scenario_file\u001b[39m=\u001b[39mscenario_file)\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Default Scheduler\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/gym/envs/registration.py:235\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake\u001b[39m(\u001b[39mid\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mmake(\u001b[39mid\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/gym/envs/registration.py:129\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mMaking new env: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, path)\n\u001b[1;32m    128\u001b[0m spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspec(path)\n\u001b[0;32m--> 129\u001b[0m env \u001b[39m=\u001b[39m spec\u001b[39m.\u001b[39;49mmake(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m env\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/gym/envs/registration.py:90\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m load(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentry_point)\n\u001b[0;32m---> 90\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwargs)\n\u001b[1;32m     92\u001b[0m \u001b[39m# Make the environment aware of which spec it came from.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m spec \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/envs/sim_kube_env.py:27\u001b[0m, in \u001b[0;36mSimKubeEnv.__init__\u001b[0;34m(self, reward_file, scenario_file, n_node, cpu_pool, mem_pool, debug)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_fn_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_file)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenario_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mtrace2017\u001b[39m\u001b[39m'\u001b[39m, scenario_file) \u001b[39mif\u001b[39;00m scenario_file\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mtrace2017\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m scenario_file\n\u001b[0;32m---> 27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstress_gen \u001b[39m=\u001b[39m SimStressGen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscenario_file, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdebug)\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_node \u001b[39m=\u001b[39m n_node\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcpu_pool \u001b[39m=\u001b[39m cpu_pool\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/utils/sim_stress_gen.py:17\u001b[0m, in \u001b[0;36mSimStressGen.__init__\u001b[0;34m(self, scenario_file, debug)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m=\u001b[39m debug\n\u001b[1;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenario_file \u001b[39m=\u001b[39m scenario_file\n\u001b[0;32m---> 17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscenario \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_scenario(scenario_file)\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/utils/sim_stress_gen.py:26\u001b[0m, in \u001b[0;36mSimStressGen.load_scenario\u001b[0;34m(self, scenario_file)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m(SimStressGen) Scenario path: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scenario_path))\n\u001b[1;32m     25\u001b[0m scenario \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 26\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(scenario_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     27\u001b[0m     lines \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/swkim/Documents/coding/thesis/PROMES_colab/notebook/../kube_sim_gym/utils/../../scenarios/scenario_10l-3m-1000p-10m.csv'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# Get n_scenario by counting the number of trace files in trace folder\n",
    "n_scenario = len(os.listdir(os.path.join(base_path, 'scenarios', 'trace2017')))\n",
    "\n",
    "while last_idx < n_scenario:\n",
    "    json_tracker = keep_training('tracker_ppo_promes_dynamic_new.json')\n",
    "    last_idx = json_tracker['last_scenario']\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6> PPO Naive Dynamic New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "envs = []\n",
    "for i in range(1, 101):\n",
    "    env = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    envs.append(env)\n",
    "\n",
    "print(len(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_training(json_tracker_fname):\n",
    "\n",
    "    log_name = json_tracker_fname.split('.')[0]\n",
    "    log_path = 'training/log/' + log_name\n",
    "\n",
    "    # Load the json tracker\n",
    "    import json\n",
    "    with open(f'training/{json_tracker_fname}', 'r') as f:\n",
    "        json_tracker = json.load(f)\n",
    "\n",
    "    # Check if the last scenario is None\n",
    "    if json_tracker['last_scenario'] == 0:\n",
    "        # If it is None, then start from the first scenario\n",
    "        scenario_idx = 1\n",
    "    else:\n",
    "        # If it is not None, then continue from the last scenario\n",
    "        scenario_idx = int(json_tracker['last_scenario']) + 1\n",
    "\n",
    "    # Load the last scenario\n",
    "    env = envs[scenario_idx - 1]\n",
    "    print(f\"Loading the scenario: {env.scenario_file}\")\n",
    "\n",
    "    # Load the last model. If there is model_name doesn't exist in training/model folder, then start from the scratch\n",
    "    model_name = json_tracker['model_name']\n",
    "    if os.path.exists(f'training/model/{model_name}.zip'):\n",
    "        print(f\"Loading the model: {model_name}\")\n",
    "        model = sb3.PPO.load(f'training/model/{model_name}.zip')\n",
    "        # Set the environment\n",
    "        model.set_env(env)\n",
    "    else:\n",
    "        print(f\"Model {model_name} doesn't exist. Start from the scratch.\")\n",
    "        model = sb3.PPO('MlpPolicy', env, verbose=1, policy_kwargs=policy_kwargs_naive)\n",
    "        model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "\n",
    "\n",
    "    # ============================== Performance Test ===============================\n",
    "\n",
    "    # Previous model performance test (vs. defautl scheduler)\n",
    "    # Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=f'scenario-5l-5m-1000p-10m.csv')\n",
    "\n",
    "    # Default Scheduler\n",
    "    from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "    default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "    # RL Scheduler\n",
    "    from kube_rl_scheduler.scheduler.sim_rl_scheduler import SimRlScheduler\n",
    "    rl_scheduler = SimRlScheduler(test_env1, f'_{model_name}.zip')\n",
    "\n",
    "\n",
    "    # Test the model\n",
    "    obs1 = test_env1.reset()\n",
    "    obs2 = test_env2.reset()\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    step1 = 0\n",
    "    step2 = 0\n",
    "    acc_rew1 = 0\n",
    "    acc_rew2 = 0\n",
    "\n",
    "    print(\"Start testing...\")\n",
    "    while not done1 or not done2:\n",
    "        if not done1:\n",
    "            # action1, _ = model.predict(obs1)\n",
    "            action1 = rl_scheduler.decision(test_env1)\n",
    "            obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "            step1 += 1\n",
    "            acc_rew1 += reward1\n",
    "        if not done2:\n",
    "            action2 = default_scheduler.decision(test_env2)\n",
    "            obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "            step2 += 1\n",
    "            acc_rew2 += reward2\n",
    "\n",
    "    acc_rew1 = round(acc_rew1, 2)\n",
    "    acc_rew2 = round(acc_rew2, 2)\n",
    "\n",
    "    print(f\"Test result(reward): {acc_rew1} vs. {acc_rew2}\")\n",
    "    print(f\"Test result(step): {step1} vs. {step2}\")\n",
    "\n",
    "    # Append it to the log file\n",
    "\n",
    "    # Make folder if it doesn't exist\n",
    "    if not os.path.exists(f'training/log/{log_name}'):\n",
    "        os.makedirs(f'training/log/{log_name}')\n",
    "\n",
    "    with open(f'training/log/{log_name}/test_result.txt', 'a') as f:\n",
    "        f.write(\"step, d_reward, d_step, p_reward, p_step\\n\")\n",
    "        f.write(f\"{scenario_idx - 1}, {acc_rew2}, {step2}, {acc_rew1}, {step1}\\n\")\n",
    "\n",
    "    # ============================== ==================== ===============================\n",
    "\n",
    "    total_timesteps = json_tracker['total_steps']\n",
    "\n",
    "    # Start training\n",
    "    model.learn(total_timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'training/model/{model_name}.zip')\n",
    "\n",
    "    # Update the json tracker\n",
    "    json_tracker['last_scenario'] = scenario_idx\n",
    "\n",
    "    # Save the json tracker\n",
    "    with open(f'training/{json_tracker_fname}', 'w') as f:\n",
    "        json.dump(json_tracker, f)\n",
    "\n",
    "    return json_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the scenario: trace2017/trace2017_100_9.csv\n",
      "Loading the model: PPO_Naive_Dynamic_New\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ActorCriticPolicy:\n\tMissing key(s) in state_dict: \"features_extactor.net.net3_.fc1_1.weight\", \"features_extactor.net.net3_.fc1_1.bias\", \"features_extactor.net.net3_.fc1_2.weight\", \"features_extactor.net.net3_.fc1_2.bias\", \"features_extactor.net.net3_.fc2.weight\", \"features_extactor.net.net3_.fc2.bias\", \"features_extactor.net.net3_.fc3.weight\", \"features_extactor.net.net3_.fc3.bias\", \"features_extactor.net.fc1_3_1.weight\", \"features_extactor.net.fc1_3_1.bias\", \"features_extactor.net.fc1_3_2.weight\", \"features_extactor.net.fc1_3_2.bias\", \"features_extactor.net.fc1_3_3.weight\", \"features_extactor.net.fc1_3_3.bias\", \"features_extactor.net.fc1_3_4.weight\", \"features_extactor.net.fc1_3_4.bias\", \"features_extactor.net.fc1_3_5.weight\", \"features_extactor.net.fc1_3_5.bias\", \"features_extactor.net.fc2_1.weight\", \"features_extactor.net.fc2_1.bias\", \"features_extactor.net.fc2_2.weight\", \"features_extactor.net.fc2_2.bias\", \"features_extactor.net.fc2_3.weight\", \"features_extactor.net.fc2_3.bias\", \"features_extactor.net.fc2_4.weight\", \"features_extactor.net.fc2_4.bias\", \"features_extactor.net.fc2_5.weight\", \"features_extactor.net.fc2_5.bias\". \n\tUnexpected key(s) in state_dict: \"features_extractor.net.weight\", \"features_extractor.net.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m n_scenario \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m'\u001b[39m\u001b[39mscenarios\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrace2017\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m last_idx \u001b[39m<\u001b[39m n_scenario:\n\u001b[0;32m----> 9\u001b[0m     json_tracker \u001b[39m=\u001b[39m keep_training(\u001b[39m'\u001b[39;49m\u001b[39mtracker_ppo_naive_dynamic_new.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m     last_idx \u001b[39m=\u001b[39m json_tracker[\u001b[39m'\u001b[39m\u001b[39mlast_scenario\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 50\u001b[0m, in \u001b[0;36mkeep_training\u001b[0;34m(json_tracker_fname)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m# RL Scheduler\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkube_rl_scheduler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscheduler\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msim_rl_scheduler\u001b[39;00m \u001b[39mimport\u001b[39;00m SimRlScheduler\n\u001b[0;32m---> 50\u001b[0m rl_scheduler \u001b[39m=\u001b[39m SimRlScheduler(test_env1, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m.zip\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     53\u001b[0m \u001b[39m# Test the model\u001b[39;00m\n\u001b[1;32m     54\u001b[0m obs1 \u001b[39m=\u001b[39m test_env1\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Documents/coding/thesis/PROMES_colab/notebook/../kube_rl_scheduler/scheduler/sim_rl_scheduler.py:197\u001b[0m, in \u001b[0;36mSimRlScheduler.__init__\u001b[0;34m(self, env, model_fname)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m ActorCriticPolicy(env, feature_dim\u001b[39m=\u001b[39mfeature_dim)\n\u001b[1;32m    195\u001b[0m \u001b[39m# print(f\"model: {self.model}\")\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mload_state_dict(model_policy\u001b[39m.\u001b[39;49mstate_dict())\n\u001b[1;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kube-gym/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ActorCriticPolicy:\n\tMissing key(s) in state_dict: \"features_extactor.net.net3_.fc1_1.weight\", \"features_extactor.net.net3_.fc1_1.bias\", \"features_extactor.net.net3_.fc1_2.weight\", \"features_extactor.net.net3_.fc1_2.bias\", \"features_extactor.net.net3_.fc2.weight\", \"features_extactor.net.net3_.fc2.bias\", \"features_extactor.net.net3_.fc3.weight\", \"features_extactor.net.net3_.fc3.bias\", \"features_extactor.net.fc1_3_1.weight\", \"features_extactor.net.fc1_3_1.bias\", \"features_extactor.net.fc1_3_2.weight\", \"features_extactor.net.fc1_3_2.bias\", \"features_extactor.net.fc1_3_3.weight\", \"features_extactor.net.fc1_3_3.bias\", \"features_extactor.net.fc1_3_4.weight\", \"features_extactor.net.fc1_3_4.bias\", \"features_extactor.net.fc1_3_5.weight\", \"features_extactor.net.fc1_3_5.bias\", \"features_extactor.net.fc2_1.weight\", \"features_extactor.net.fc2_1.bias\", \"features_extactor.net.fc2_2.weight\", \"features_extactor.net.fc2_2.bias\", \"features_extactor.net.fc2_3.weight\", \"features_extactor.net.fc2_3.bias\", \"features_extactor.net.fc2_4.weight\", \"features_extactor.net.fc2_4.bias\", \"features_extactor.net.fc2_5.weight\", \"features_extactor.net.fc2_5.bias\". \n\tUnexpected key(s) in state_dict: \"features_extractor.net.weight\", \"features_extractor.net.bias\". "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "last_idx = 0\n",
    "\n",
    "# Get n_scenario by counting the number of trace files in trace folder\n",
    "n_scenario = len(os.listdir(os.path.join(base_path, 'scenarios', 'trace2017')))\n",
    "\n",
    "while last_idx < n_scenario:\n",
    "    json_tracker = keep_training('tracker_ppo_naive_dynamic_new.json')\n",
    "    last_idx = json_tracker['last_scenario']\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "test_envs = []\n",
    "for i in range(1, 11):\n",
    "    test_env1 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    test_env2 = gym.make('SimKubeEnv-v0', reward_file='promes_dynamic_new.py', scenario_file=f'trace2017_100_{i}.csv')\n",
    "    test_envs.append((test_env1, test_env2))\n",
    "\n",
    "print(len(test_envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Start testing...\n",
      "Intermediary result at step 1026\n",
      "reward : -17.205099999999987(my) vs. 59.01179999999993(default)\n",
      "step : 1026(my) vs. 1025(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 2084\n",
      "reward : 38.86790000000002(my) vs. 207.11390000000003(default)\n",
      "step : 2084(my) vs. 2082(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 3085\n",
      "reward : 84.77629999999992(my) vs. 331.67520000000025(default)\n",
      "step : 3085(my) vs. 3083(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 4196\n",
      "reward : 277.7597999999999(my) vs. 594.0169999999999(default)\n",
      "step : 4196(my) vs. 4195(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 5197\n",
      "reward : 270.4608999999997(my) vs. 690.4779(default)\n",
      "step : 5197(my) vs. 5196(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 6225\n",
      "reward : 322.9045999999997(my) vs. 796.0006999999981(default)\n",
      "step : 6225(my) vs. 6224(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 7449\n",
      "reward : 413.86659999999944(my) vs. 981.1039999999987(default)\n",
      "step : 7448(my) vs. 7449(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 8457\n",
      "reward : 447.7192999999999(my) vs. 1137.3780999999992(default)\n",
      "step : 8457(my) vs. 8456(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 9592\n",
      "reward : 504.32880000000085(my) vs. 1256.7872000000004(default)\n",
      "step : 9592(my) vs. 9592(default)\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Intermediary result at step 11170\n",
      "reward : 757.9768000000005(my) vs. 1601.9591000000019(default)\n",
      "step : 11170(my) vs. 11162(default)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep : \u001b[39m\u001b[39m{\u001b[39;00mstep1\u001b[39m}\u001b[39;00m\u001b[39m(my) vs. \u001b[39m\u001b[39m{\u001b[39;00mstep2\u001b[39m}\u001b[39;00m\u001b[39m(default)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m scenario_cnt1 \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 66\u001b[0m test_env1 \u001b[39m=\u001b[39m test_envs[scenario_cnt1][\u001b[39m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m rl_scheduler \u001b[39m=\u001b[39m SimRlScheduler(test_env1, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m obs1 \u001b[39m=\u001b[39m test_env1\u001b[39m.\u001b[39mreset()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from kube_sim_gym.envs.sim_kube_env import SimKubeEnv\n",
    "\n",
    "model_name = 'PPO_Naive_Dynamic_New' # Change model name\n",
    "reward_file = 'promes_dynamic_new.py' # Change reward file name\n",
    "\n",
    "# Previous model performance test (vs. defautl scheduler)\n",
    "# Test scenario : scenario-5l-5m-1000p-10m.csv\n",
    "test_env1 = test_envs[0][0]\n",
    "test_env2 = test_envs[0][1]\n",
    "\n",
    "# RL Scheduler\n",
    "from kube_rl_scheduler.scheduler.sim_rl_scheduler import SimRlScheduler\n",
    "rl_scheduler = SimRlScheduler(test_env2, f'_{model_name}.zip')\n",
    "# Default Scheduler\n",
    "from kube_hr_scheduler.scheduler.sim_hr_scheduler import SimHrScheduler\n",
    "default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "\n",
    "# Test the model\n",
    "obs1 = test_env1.reset()\n",
    "obs2 = test_env2.reset()\n",
    "done1 = False\n",
    "done2 = False\n",
    "scenario_cnt1 = 0\n",
    "scenario_cnt2 = 0\n",
    "step1 = 0\n",
    "step2 = 0\n",
    "acc_rew1 = 0\n",
    "acc_rew2 = 0\n",
    "\n",
    "print(\"Start testing...\")\n",
    "\n",
    "while (not done1 and scenario_cnt1 != 9) or (not done2 and scenario_cnt2 != 9):\n",
    "    if not done1:\n",
    "        # action1, _ = model.predict(obs1)\n",
    "        action1 = rl_scheduler.decision(test_env1)\n",
    "        obs1, reward1, done1, _ = test_env1.step(action1)\n",
    "        step1 += 1\n",
    "        acc_rew1 += reward1\n",
    "    if not done2:\n",
    "        action2 = default_scheduler.decision(test_env2)\n",
    "        obs2, reward2, done2, _ = test_env2.step(action2)\n",
    "        step2 += 1\n",
    "        acc_rew2 += reward2\n",
    "\n",
    "    # if done1:\n",
    "    #     scenario_cnt1 += 1\n",
    "    #     test_env1 = test_envs[scenario_cnt1][0]\n",
    "    #     rl_scheduler = SimRlScheduler(test_env1, f'_{model_name}.zip')\n",
    "    #     obs1 = test_env1.reset()\n",
    "    #     # done1 = False\n",
    "    # if done2:\n",
    "    #     scenario_cnt2 += 1\n",
    "    #     test_env2 = test_envs[scenario_cnt2][1]\n",
    "    #     default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "    #     obs2 = test_env2.reset()\n",
    "    #     # done2 = False\n",
    "\n",
    "    if done1 and done2:\n",
    "\n",
    "        print(f\"Intermediary result at step {step1 if step1 > step2 else step2}\")\n",
    "        print(f\"reward : {acc_rew1}(my) vs. {acc_rew2}(default)\")\n",
    "        print(f\"step : {step1}(my) vs. {step2}(default)\")\n",
    "\n",
    "        scenario_cnt1 += 1\n",
    "        test_env1 = test_envs[scenario_cnt1][0]\n",
    "        rl_scheduler = SimRlScheduler(test_env1, f'_{model_name}.zip')\n",
    "        obs1 = test_env1.reset()\n",
    "        done1 = False\n",
    "\n",
    "        scenario_cnt2 += 1\n",
    "        test_env2 = test_envs[scenario_cnt2][1]\n",
    "        default_scheduler = SimHrScheduler(test_env2, 'default.py')\n",
    "        obs2 = test_env2.reset()\n",
    "        done2 = False\n",
    "\n",
    "\n",
    "acc_rew1 = round(acc_rew1, 2)\n",
    "acc_rew2 = round(acc_rew2, 2)\n",
    "\n",
    "print(\"Fianl result\")\n",
    "print(f\"reward : {acc_rew1}(my) vs. {acc_rew2}(default)\")\n",
    "print(f\"step : {step1}(my) vs. {step2}(default)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kube-gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
